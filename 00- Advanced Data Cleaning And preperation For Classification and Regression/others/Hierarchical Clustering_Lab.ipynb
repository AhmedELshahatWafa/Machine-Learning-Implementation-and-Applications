{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Hierarchical Clustering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"#1\">Read the dataset</a>\n",
    "2. <a href=\"#2\">Data investigation</a>\n",
    "3. <a href=\"#3\">Data preprocessing </a>\n",
    "4. <a href=\"#4\">Features transformation </a>\n",
    "4. <a href=\"#5\">Training datasets</a>\n",
    "5. <a href=\"#6\">Improvement ideas</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "First dowmload the data set from this link https://www.kaggle.com/fernandol/countries-of-the-world\n",
    "then import it in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (227, 20)\n"
     ]
    }
   ],
   "source": [
    "#read the data\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "\n",
    "data_path = 'countries of the world.csv'  #the path where you downloaded the data\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)\n",
    "\n",
    "# Renaming columns\n",
    "df.rename(columns={\"Area (sq. mi.)\" : \"Area\",\"Pop. Density (per sq. mi.)\" : \"PopDensity\",\"Coastline (coast/area ratio)\": \"Coastline\",\"Net migration\":\"NetMigration\",\"Infant mortality (per 1000 births)\" :\"InfantMortality\",\"GDP ($ per capita)\": \"GDP\",\"Literacy (%)\" : \"Literacy\",\"Phones (per 1000)\" : \"Phones\",\"Arable (%)\" : \"Arable\",\"Crops (%)\" : \"Crops\",\"Other (%)\" : \"Other\",\"Climate\" : \"Climate\",\"Birthrate\" : \"Birthrate\",\"Deathrate\" : \"Deathrate\",\"Agriculture\": \"Agriculture\",\"Industry\" : \"Industry\",\"Service\"  : \"Service\"},inplace=True)\n",
    "\n",
    "#Dropping the only one with GDP NaN \n",
    "df =  df[df[\"GDP\"].notna()]\n",
    "\n",
    "# Getting num cols\n",
    "num_cols = ['PopDensity','Coastline','NetMigration','InfantMortality','Literacy','Phones','Arable','Crops','Other','Climate','Birthrate','Deathrate','Agriculture','Industry','Service']\n",
    "\n",
    "# Converting commas to floating points\n",
    "for i in num_cols:\n",
    "    #print(i)\n",
    "    df[i] = df[i].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    \n",
    "# this is telling us that there is  \n",
    "\n",
    "unique, counts = np.unique(np.sort(df.isna().T.sum()), return_counts=True)\n",
    "np.asarray((unique, counts)).T\n",
    "# array([[  0, 179],\n",
    "#        [  1,  28],\n",
    "#        [  2,   1],\n",
    "#        [  3,   8],\n",
    "#        [  4,   7],\n",
    "#        [  5,   1],\n",
    "#        [  7,   2]], dtype=int64)\n",
    "\n",
    "#using this info we can drop all row with four or more missing values\n",
    "df = df.dropna(thresh = df.shape[1] - 3)\n",
    "\n",
    "#filling the rest missing\n",
    "\n",
    "#filling last three with nans\n",
    "fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df_nums = df[num_cols]\n",
    "imputed_DF = pd.DataFrame(fill_NaN.fit_transform(df_nums))\n",
    "imputed_DF.columns = df_nums.columns\n",
    "imputed_DF.index = df_nums.index\n",
    "\n",
    "df[num_cols] = imputed_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data investigation</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "in this part you need to check the data quality and assess any issues in the data as:\n",
    "- null values in each column \n",
    "- each column has the proper data type\n",
    "- outliers\n",
    "- duplicate rows\n",
    "- distribution for each column (skewness)\n",
    "<br>\n",
    "\n",
    "**comment each issue you find** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 20 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Country                             227 non-null    object \n",
      " 1   Region                              227 non-null    object \n",
      " 2   Population                          227 non-null    int64  \n",
      " 3   Area (sq. mi.)                      227 non-null    int64  \n",
      " 4   Pop. Density (per sq. mi.)          227 non-null    object \n",
      " 5   Coastline (coast/area ratio)        227 non-null    object \n",
      " 6   Net migration                       224 non-null    object \n",
      " 7   Infant mortality (per 1000 births)  224 non-null    object \n",
      " 8   GDP ($ per capita)                  226 non-null    float64\n",
      " 9   Literacy (%)                        209 non-null    object \n",
      " 10  Phones (per 1000)                   223 non-null    object \n",
      " 11  Arable (%)                          225 non-null    object \n",
      " 12  Crops (%)                           225 non-null    object \n",
      " 13  Other (%)                           225 non-null    object \n",
      " 14  Climate                             205 non-null    object \n",
      " 15  Birthrate                           224 non-null    object \n",
      " 16  Deathrate                           223 non-null    object \n",
      " 17  Agriculture                         212 non-null    object \n",
      " 18  Industry                            211 non-null    object \n",
      " 19  Service                             212 non-null    float64\n",
      "dtypes: float64(2), int64(2), object(16)\n",
      "memory usage: 35.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's see the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The only two columns that are  string are (country and region)\n",
    "## we can t see that in the data types of the info() output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                                0\n",
       "Region                                 0\n",
       "Population                             0\n",
       "Area (sq. mi.)                         0\n",
       "Pop. Density (per sq. mi.)             0\n",
       "Coastline (coast/area ratio)           0\n",
       "Net migration                          3\n",
       "Infant mortality (per 1000 births)     3\n",
       "GDP ($ per capita)                     1\n",
       "Literacy (%)                          18\n",
       "Phones (per 1000)                      4\n",
       "Arable (%)                             2\n",
       "Crops (%)                              2\n",
       "Other (%)                              2\n",
       "Climate                               22\n",
       "Birthrate                              3\n",
       "Deathrate                              4\n",
       "Agriculture                           15\n",
       "Industry                              16\n",
       "Service                               15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                               0.00\n",
       "Region                                0.00\n",
       "Population                            0.00\n",
       "Area (sq. mi.)                        0.00\n",
       "Pop. Density (per sq. mi.)            0.00\n",
       "Coastline (coast/area ratio)          0.00\n",
       "Net migration                         1.32\n",
       "Infant mortality (per 1000 births)    1.32\n",
       "GDP ($ per capita)                    0.44\n",
       "Literacy (%)                          7.93\n",
       "Phones (per 1000)                     1.76\n",
       "Arable (%)                            0.88\n",
       "Crops (%)                             0.88\n",
       "Other (%)                             0.88\n",
       "Climate                               9.69\n",
       "Birthrate                             1.32\n",
       "Deathrate                             1.76\n",
       "Agriculture                           6.61\n",
       "Industry                              7.05\n",
       "Service                               6.61\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isnull().sum(axis=0)*100/df.shape[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (sq. mi.)</th>\n",
       "      <th>GDP ($ per capita)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.874028e+07</td>\n",
       "      <td>5.982270e+05</td>\n",
       "      <td>9689.823009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178913e+08</td>\n",
       "      <td>1.790282e+06</td>\n",
       "      <td>10049.138513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.026000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.376240e+05</td>\n",
       "      <td>4.647500e+03</td>\n",
       "      <td>1900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.786994e+06</td>\n",
       "      <td>8.660000e+04</td>\n",
       "      <td>5550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.749777e+07</td>\n",
       "      <td>4.418110e+05</td>\n",
       "      <td>15700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.313974e+09</td>\n",
       "      <td>1.707520e+07</td>\n",
       "      <td>55100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Population  Area (sq. mi.)  GDP ($ per capita)\n",
       "count  2.270000e+02    2.270000e+02          226.000000\n",
       "mean   2.874028e+07    5.982270e+05         9689.823009\n",
       "std    1.178913e+08    1.790282e+06        10049.138513\n",
       "min    7.026000e+03    2.000000e+00          500.000000\n",
       "25%    4.376240e+05    4.647500e+03         1900.000000\n",
       "50%    4.786994e+06    8.660000e+04         5550.000000\n",
       "75%    1.749777e+07    4.418110e+05        15700.000000\n",
       "max    1.313974e+09    1.707520e+07        55100.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will print basic statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Data preprocessing</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define below all the issues that you had found in the previous part\n",
    "1-           <br>\n",
    "2-           <br>\n",
    "3-           <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy for the original dataset\n",
    "df_copy=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each issue adapt this methodology \n",
    "- start by defining the solution\n",
    "- apply this solution onn the data\n",
    "- test the solution to make sure that you have solved the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First issue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second issue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Features transformation</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the feature scaling technique that would use and why?* <br>\n",
    "*return to this section again and try another technique and see how that will impact your result*<br>\n",
    "for more details on different methods for scaling check these links\n",
    "- https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "- https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Training and hyperparamter tuning</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training process we need to specify 3 paramters:<br>\n",
    "1- Linkage criteria : The linkage criterion determines the distance between two clusters\n",
    "    - Complete-Linkage Clustering\n",
    "    - Single-Linkage Clustering\n",
    "    - Average-Linkage Clustering\n",
    "    - Centroid Linkage Clustering\n",
    "2- Distance function:\n",
    "    - Euclidean Distance \n",
    "    - Manhattan Distance \n",
    "    - Mahalanobis distance \n",
    "3- Number of clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Number of clusters*\n",
    "Use Dendograms to specify the optimum number of clusters\n",
    "- Compare how changing linkage criteria or distance function would affect the optimum number of clusters\n",
    "- you can use silhouette_score or any other evalution method to help you determine the optimum number of clusters\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Counters Dendograms\")\n",
    "dend = shc.dendrogram(shc.linkage(y=... , method=...,metric=...),orientation='right') #fill y with your dataframe\n",
    "                                                                                      #and method with linkage criteria\n",
    "                                                                                      #and metric with distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a name=\"6\">improvement ideas</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try to use PCA to reduce the number of features and compare how this will affect the clustring process\n",
    "- Try to run your code again but with different tranformation technique\n",
    "- Implement gap statistics method and use it as evaluation metric and compare the result with what you did before https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/#gap-statistic-method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
